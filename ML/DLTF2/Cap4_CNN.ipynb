{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Cap4 CNN.ipynb","provenance":[{"file_id":"1Rr2JC2OGB76Un5wkJirYY8Fnm-KaZyZw","timestamp":1618775013768}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"suburban-examination"},"source":["\n","# Redes Neuronales Convolucionales \n","por Raziel López Escamilla.\n","\n","#Introducción.\n","\n","Las redes neuronales convolucionales consisten en múltiples capas de filtros convolucionales de una o más dimensiones. Después de cada capa, por lo general se añade una función para realizar un mapeo causal no-lineal.\n","\n","Este tipo de red es una variación de un perceptron multicapa, sin embargo, debido a que su aplicación es realizada en matrices bidimensionales, son muy efectivas para tareas de visión artificial, como en la clasificación y segmentación de imágenes, entre otras aplicaciones\n","\n","A continuacion se mostrará un ejempo de una red CNN utilizando TensorFlow"],"id":"suburban-examination"},{"cell_type":"markdown","metadata":{"id":"greatest-effort"},"source":["MNIST_V_9"],"id":"greatest-effort"},{"cell_type":"markdown","metadata":{"id":"aQ8p-bsshV3L"},"source":["Importar libreriras"],"id":"aQ8p-bsshV3L"},{"cell_type":"code","metadata":{"id":"legitimate-helping"},"source":["import tensorflow as tf        #Tensorflow\n","import numpy as np             #numpy \n","from tensorflow import keras   # Keras "],"id":"legitimate-helping","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mechanical-respondent"},"source":["Librería Mnist y tratamos ls datos \n","(28x28x1)---blanco/negro     (28x28x3) RGB----- a color "],"id":"mechanical-respondent"},{"cell_type":"code","metadata":{"id":"expressed-burke"},"source":["#  Parámetros \n","EPOCHS = 3          \n","BATCH_SIZE = 220     #Batch size\n","VERBOSE = 2         \n","NB_CLASSES = 10      #digits from 0 to 9\n","N_HIDDEN = 2048      \n","VALIDATION_SPLIT=0.999 # how much TRAIN is reserved for VALIDATION\n","DROPOUT = 0.5          # Droput para overfiting "],"id":"expressed-burke","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLjqTMrFhkor"},"source":["Cargar el MNSIST para el dataset"],"id":"YLjqTMrFhkor"},{"cell_type":"code","metadata":{"id":"centered-black"},"source":["# verify\n","# the split between train and test is 60,000, and 10,000 respectly \n","# one-hot is automatically applied\n","mnist = keras.datasets.mnist                               #dataset de mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()   #Cargamos el dataset "],"id":"centered-black","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44MFizVhhvYD"},"source":["Se agrega formato a los arreglos de prueba y de entrenamiento."],"id":"44MFizVhhvYD"},{"cell_type":"code","metadata":{"id":"australian-mississippi"},"source":["#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n","RESHAPED = 784\n","#\n","X_train = X_train.reshape(60000, RESHAPED)     \n","X_test = X_test.reshape(10000, RESHAPED)       \n","X_train = X_train.astype('float32')             \n","X_test = X_test.astype('float32')            "],"id":"australian-mississippi","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PfEv78XLh3Kj"},"source":["Se normalizan los arreglos."],"id":"PfEv78XLh3Kj"},{"cell_type":"code","metadata":{"id":"measured-tournament","outputId":"80551569-d87d-46e7-f6c8-94872f3e4381"},"source":["#normalize in [0,1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0      \n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"],"id":"measured-tournament","execution_count":null,"outputs":[{"output_type":"stream","text":["60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vmCYogKAiBPB"},"source":["Se representa de forma vectorial."],"id":"vmCYogKAiBPB"},{"cell_type":"code","metadata":{"id":"grand-climate"},"source":["#one-hot\n","Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)       \n","Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"],"id":"grand-climate","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unusual-movement"},"source":["Creación del modelo con 3 capas con un modelo secuancial\n","\n"],"id":"unusual-movement"},{"cell_type":"code","metadata":{"id":"opposite-training"},"source":["#build the model\n","model = tf.keras.models.Sequential()                  \n","\n","model.add(keras.layers.Dense(N_HIDDEN,                 \n","   \t\tinput_shape=(RESHAPED,),\n","   \t\tname='dense_layer', activation='relu'))        \n","model.add(keras.layers.Dropout(DROPOUT))\n"," \n","model.add(keras.layers.Dense(N_HIDDEN,                \n","   \t\tname='dense_layer_2', activation='relu'))\n","model.add(keras.layers.Dropout(DROPOUT))               \n","\n","model.add(keras.layers.Dense(NB_CLASSES,              \n","   \t\tname='dense_layer_3', activation='softmax'))"],"id":"opposite-training","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oWUdx0kilIE"},"source":["Se muestra un resumen del modelo"],"id":"7oWUdx0kilIE"},{"cell_type":"code","metadata":{"scrolled":true,"id":"cutting-highland","outputId":"4a3f205a-68da-4cbc-bb4c-933f1ca98892"},"source":["# summary of the model\n","model.summary()                       "],"id":"cutting-highland","execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_layer (Dense)          (None, 2048)              1607680   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense_layer_2 (Dense)        (None, 2048)              4196352   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_layer_3 (Dense)        (None, 10)                20490     \n","=================================================================\n","Total params: 5,824,522\n","Trainable params: 5,824,522\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"moving-cocktail"},"source":["compilamos el modelo, utilizando optimizador adam, funcion de perdida y calculando la precisión del modelo. "],"id":"moving-cocktail"},{"cell_type":"code","metadata":{"id":"legal-telling"},"source":["# compiling the model\n","model.compile(optimizer='Adam',                    \n","              loss='categorical_crossentropy',    \n","              metrics=['accuracy'])   "],"id":"legal-telling","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uwl0XYEhVEEf"},"source":["entrenamiento del modelo"],"id":"uwl0XYEhVEEf"},{"cell_type":"code","metadata":{"id":"compatible-reunion","outputId":"26c2fed8-af0a-42b5-9c84-ce91c85d235c"},"source":["#training the moodel                                            #entrenamos el modelo \n","model.fit(X_train, Y_train,\n","\t\tbatch_size=BATCH_SIZE, epochs=EPOCHS,                   \n","\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"],"id":"compatible-reunion","execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","1/1 - 4s - loss: 2.2656 - accuracy: 0.1833 - val_loss: 2.0427 - val_accuracy: 0.3163\n","Epoch 2/3\n","1/1 - 3s - loss: 1.7614 - accuracy: 0.5167 - val_loss: 1.7424 - val_accuracy: 0.4684\n","Epoch 3/3\n","1/1 - 3s - loss: 1.2397 - accuracy: 0.7000 - val_loss: 1.4350 - val_accuracy: 0.5910\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x22934a6edf0>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"B4onB16dVHRX"},"source":["Evaluamos el modelo y se calcula presición."],"id":"B4onB16dVHRX"},{"cell_type":"code","metadata":{"id":"dedicated-nashville","outputId":"d67b3da0-ca90-42d5-8325-750fee21be09"},"source":["test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"id":"dedicated-nashville","execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 2s 7ms/step - loss: 1.4329 - accuracy: 0.5857\n","Test accuracy: 0.5856999754905701\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QPNnUIV4VL3J"},"source":["Hacemos una predicción "],"id":"QPNnUIV4VL3J"},{"cell_type":"code","metadata":{"id":"wired-internet","outputId":"21690389-6eef-4f7b-b130-a54917343bf3"},"source":["predictions = model.predict(X_test)\n","print(predictions)"],"id":"wired-internet","execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.06224658 0.05407007 0.10215508 ... 0.1660852  0.09695984 0.26234508]\n"," [0.08884829 0.12121257 0.11924042 ... 0.03204749 0.06090078 0.02887413]\n"," [0.04789393 0.37023085 0.05925105 ... 0.05711152 0.08973812 0.07316941]\n"," ...\n"," [0.01285272 0.04867186 0.04534056 ... 0.0558794  0.10805231 0.4761033 ]\n"," [0.07834467 0.20341018 0.07541793 ... 0.05883632 0.15121335 0.13986273]\n"," [0.21576425 0.05685443 0.06157725 ... 0.02991032 0.02457118 0.01348476]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AwHySv_EjI4d"},"source":["##Conclusion.\n","\n","Dada a la naturaleza de las convoluciones dentro de las redes neuronales convolucionales, estas son aptas para poder aprender a clasificar todo tipo de datos donde estos estén distribuidos de una forma continua a lo largo del mapa de entrada, y a su vez sean estadísticamente similares en cualquier lugar del mapa de entrada. Por esta razón, son especialmente eficaces para clasificar imágenes, por ejemplo para el auto-etiquetado de imágenes.\n","\n","Sin embargo, las redes neuronales convolucionales también pueden ser aplicadas para la clasificación de series de tiempo o señales de audio utilizando convoluciones en una dimension, así como para la clasificación de datos volumétricos usando convoluciones en 3D"],"id":"AwHySv_EjI4d"}]}