{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cap6 GAN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z7WUiSO8bDt1"},"source":["#Generative Adversarial Network (GAN)\n","por Raziel Lopez Escamilla,\n","\n","Dentro de las aplicaciones de las GAN estan la creación de imágenes, videos, música e incluso lenguajes naturales. Este tipo de redes se han empleado en tareas como traducción de imagen a imagen, súper resolución de imagen, descubrimiento de fármacos e incluso predicción del siguiente fotograma en video.\n","\n","La idea clave de GAN se puede entender fácilmente considerándola análoga a la \"falsificación de arte\", que es el proceso de creación de obras de arte que se atribuyen falsamente a otros artistas generalmente más famosos. \n","\n","Las GAN entrenan dos redes neuronales simultáneamente, son:\n","\n","*   El generador G (Z) es el que realiza la falsificación.\n","*   El discriminador D (Y) es el que puede juzgar cuán realistas son las \n","reproducciones, basandose en observaciones de auténticas obras de arte y copias.\n","\n","D (Y) toma una entrada Y (por ejemplo, una imagen) y expresa un voto para juzgar qué tan real es la entrada. \n","\n","En general, un valor cercano a 1 denota \"real\", mientras que un valor cercano a 0 denota \"falsificación\".\n","\n","Por otra parte, G (Z) toma una entrada del ruido aleatorio Z y se entrena a sí mismo para engañar a D haciéndole pensar que todo lo que produce G (Z) es real.\n","\n","El objetivo de entrenar el discriminador D (Y) es maximizar D (Y) para cada imagen de la verdadera distribución de datos, y para minimizar D (Y) para cada imagen que no provenga de la verdadera distribución de datos. Entonces, G y D juegan juegos opuestos: de ahí el nombre de entrenamiento adversario.\n","\n","La red discriminadora (generalmente una red neuronal convolucional estándar) intenta clasificar si una imagen de entrada es real o generada. La nueva idea importante es propagar hacia atrás a través del discriminador y el generador para ajustar los parámetros del generador de tal manera que el generador pueda aprender a engañar al discriminador más a menudo.\n","\n","Al final, el generador aprenderá a producir imágenes indistinguibles de las reales:\n","\n","A continuacion se mostrará un ejemplo implementando una GAN con tensorflow\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f82d63_GiyxD"},"source":["#GAN simple capaz de generar dígitos escritos a mano. "]},{"cell_type":"markdown","metadata":{"id":"R9AooELli3iA"},"source":["Importamos librerias"]},{"cell_type":"code","metadata":{"id":"T01XMscEsSjQ","executionInfo":{"status":"ok","timestamp":1618810022646,"user_tz":300,"elapsed":752,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import initializers\n","\n","\n","import matplotlib.pyplot as plt\n","\n","import sys\n","\n","import numpy as np\n","import tqdm"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zibnZhutsWCa"},"source":["Se usaran los dígitos manuscritos del MNIST para entrenar la red. Los datos contienen 60.000 imágenes de entrenamiento de dígitos escritos a mano, cada uno de tamaño 28 × 28.Se normalizan los valores de entrada de modo que cada píxel tenga un valor en el rango [-1, 1]."]},{"cell_type":"code","metadata":{"id":"q18NT74askEU","executionInfo":{"status":"ok","timestamp":1618810023321,"user_tz":300,"elapsed":1421,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["# Set the seed for reproducible result\n","np.random.seed(1000)\n","\n","randomDim = 10 \n","# Load MNIST data\n","(X_train, _), (_, _) = mnist.load_data()\n","X_train = (X_train.astype(np.float32) - 127.5)/127.5\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zu3tJLMCswKu"},"source":["Usaremos un perceptrón multicapa simple (MLP) y lo alimentaremos con una imagen como un vector plano de tamaño 784, por lo que remodelamos los datos de entrenamiento."]},{"cell_type":"code","metadata":{"id":"6K_PLGvWUhbr","executionInfo":{"status":"ok","timestamp":1618810023322,"user_tz":300,"elapsed":1412,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["X_train = X_train.reshape(60000, 784)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sL2-0HpGszsk"},"source":["Se construye un generador y un discriminador."]},{"cell_type":"code","metadata":{"id":"NsansudRt17w","executionInfo":{"status":"ok","timestamp":1618810023323,"user_tz":300,"elapsed":1408,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["# Optimizer\n","adam = Adam(lr=0.0002, beta_1=0.5)\n","\n","generator = Sequential()\n","generator.add(Dense(256, input_dim=randomDim)) #, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(512))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(1024))\n","generator.add(LeakyReLU(0.2))\n","generator.add(Dense(784, activation='tanh'))\n","#generator.compile(loss='binary_crossentropy', optimizer=adam)\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5702noFjb30"},"source":["El propósito del generador es recibir una entrada ruidosa y generar una imagen similar al conjunto de datos de entrenamiento.\n","\n","El tamaño de la entrada ruidosa lo decide la variable randomDim; puede inicializarlo a cualquier valor integral. Convencionalmente, se establece en 100. Para nuestra implementación, probamos un valor de 10. \n","\n","Esta entrada se alimenta a una capa densa con 256 neuronas con activación LeakyReLU, otra capa densa con 512 neuronas ocultas, seguida de la tercera capa oculta con 1024 neuronas y finalmente la capa de salida con 784 neuronas. \n","\n","Es posible cambiar el número de neuronas en las capas ocultas y ver cómo cambia el rendimiento; sin embargo, el número de neuronas en la unidad de salida tiene que coincidir con el número de píxeles en las imágenes de entrenamiento. "]},{"cell_type":"markdown","metadata":{"id":"X75ZzoJyuOk-"},"source":["Construimos un discriminador."]},{"cell_type":"code","metadata":{"id":"rC48jtOaufrJ","executionInfo":{"status":"ok","timestamp":1618810023512,"user_tz":300,"elapsed":1594,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["discriminator = Sequential()\n","discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(512))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(256))\n","discriminator.add(LeakyReLU(0.2))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3hloOqovkXqw"},"source":["Observe que el discriminador toma las imágenes, ya sea del conjunto de entrenamiento o imágenes generadas por el generador, por lo que su tamaño de entrada es 784. Sin embargo, la salida del discriminador es un solo bit, donde 0 significa una imagen falsa (generada por el generador) y 1 significa que la imagen es del conjunto de datos de entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"MxtkEZaxuuXg"},"source":["Combinamos el generador y el discriminador para formar un GAN. \n","\n","En GAN, nos aseguramos de que los pesos del discriminador se fijen estableciendo el argumento entrenable en Falso."]},{"cell_type":"code","metadata":{"id":"eN_XosXouzE7","executionInfo":{"status":"ok","timestamp":1618810023512,"user_tz":300,"elapsed":1590,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["# Combined network\n","discriminator.trainable = False\n","ganInput = Input(shape=(randomDim,))\n","x = generator(ganInput)\n","ganOutput = discriminator(x)\n","gan = Model(inputs=ganInput, outputs=ganOutput)\n","gan.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","dLosses = []\n","gLosses = []\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kxv5XXIMxnwK"},"source":["Se calculan las perdidas y se genera una ruta para poder ingresar a MNIST y obtener la imagen.\n","\n"]},{"cell_type":"code","metadata":{"id":"JZt9RPo7vSQT","executionInfo":{"status":"ok","timestamp":1618810023513,"user_tz":300,"elapsed":1588,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["# Plot the loss from each batch\n","def plotLoss(epoch):\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(dLosses, label='Discriminitive loss')\n","    plt.plot(gLosses, label='Generative loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig('Images_GAN_Genera_%d.png' % epoch)\n","\n","# Create a wall of generated MNIST images\n","def saveGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n","    noise = np.random.normal(0, 1, size=[examples, randomDim])\n","    generatedImages = generator.predict(noise)\n","    generatedImages = generatedImages.reshape(examples, 28, 28)\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(generatedImages.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('imagenes_loss_gan_%d.png' % epoch)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QgkBD_nygSn"},"source":["Se realiza entrenamiento.\n","\n","Para cada época, se toma primero una muestra de ruido aleatorio, se alimenta al generador y el generador produce una imagen falsa. \n","\n","Se combinan las imágenes falsas generadas y las imágenes de entrenamiento reales en un lote con sus etiquetas específicas y se usan para entrenar al discriminador primero en el lote dado."]},{"cell_type":"code","metadata":{"id":"XRvKvjIQyg30","executionInfo":{"status":"ok","timestamp":1618810023699,"user_tz":300,"elapsed":1770,"user":{"displayName":"Raziel López Escamilla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7LBPygrRJVDg2ilZB221LCnDbFq_Leg7UQSi7nw=s64","userId":"15190984956973471719"}}},"source":["def train(epochs=1, batchSize=128):\n","    batchCount = int(X_train.shape[0] / batchSize)\n","    print ('Epochs:', epochs)\n","    print ('Batch size:', batchSize)\n","    print ('Batches per epoch:', batchCount)\n","\n","    for e in range(1, epochs+1):\n","        print ('-'*15, 'Epoch %d' % e, '-'*15)\n","        for _ in range(batchCount):\n","            # Get a random set of input noise and images\n","            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n","            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n","\n","            # Generate fake MNIST images\n","            generatedImages = generator.predict(noise)\n","            # print np.shape(imageBatch), np.shape(generatedImages)\n","            X = np.concatenate([imageBatch, generatedImages])\n","\n","            # Labels for generated and real data\n","            yDis = np.zeros(2*batchSize)\n","            # One-sided label smoothing\n","            yDis[:batchSize] = 0.9\n","\n","            # Train discriminator\n","            discriminator.trainable = True\n","            dloss = discriminator.train_on_batch(X, yDis)\n","\n","            # Train generator\n","            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n","            yGen = np.ones(batchSize)\n","            discriminator.trainable = False\n","            gloss = gan.train_on_batch(noise, yGen)\n","\n","        # Store loss of most recent batch from this epoch\n","        dLosses.append(dloss)\n","        gLosses.append(gloss)\n","\n","        if e == 1 or e % 20 == 0:\n","            saveGeneratedImages(e)\n","            \n","\n","    # Plot losses from every epoch\n","    plotLoss(e)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDiwD_2dykK6","outputId":"43e2d7ae-4eb9-4812-c322-bb30bb1d337f"},"source":["train(15, 128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epochs: 15\n","Batch size: 128\n","Batches per epoch: 468\n","--------------- Epoch 1 ---------------\n","--------------- Epoch 2 ---------------\n","--------------- Epoch 3 ---------------\n","--------------- Epoch 4 ---------------\n","--------------- Epoch 5 ---------------\n","--------------- Epoch 6 ---------------\n","--------------- Epoch 7 ---------------\n","--------------- Epoch 8 ---------------\n","--------------- Epoch 9 ---------------\n","--------------- Epoch 10 ---------------\n","--------------- Epoch 11 ---------------\n","--------------- Epoch 12 ---------------\n","--------------- Epoch 13 ---------------\n","--------------- Epoch 14 ---------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ziSTpNrHm_n7"},"source":["Conclusión:\n","\n","Por lo aprendido en este ejercicio GAN nos pueden ayudar a gener copias similares en estilo o forma a partir de información original, en el ejemplo aterior se necesitó de mucho entrenamiento para poder generar resultados aceptables para un humano. Actualmente, dentro del área de imagenes, las GAN han sido utilizadas para generar imagenes falsas de animales, paisajes, rostros humanos, etc."]}]}